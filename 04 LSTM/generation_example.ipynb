{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f962bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, sys\n",
    "import numpy as np\n",
    "\n",
    "from lstm import LSTMNextTokenGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c6f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Утилиты из 03 RNN/main.py\n",
    "def build_vocab(text: str):\n",
    "    chars = sorted(set(text))\n",
    "    char2idx = {ch: i for i, ch in enumerate(chars)}\n",
    "    idx2char = {i: ch for ch, i in char2idx.items()}\n",
    "    return char2idx, idx2char\n",
    "\n",
    "def encode_text(text: str, char2idx: dict[str, int]) -> np.ndarray:\n",
    "    return np.array([char2idx[ch] for ch in text], dtype=int)\n",
    "\n",
    "def to_one_hot(indices: np.ndarray, vocab_size: int) -> np.ndarray:\n",
    "    T = len(indices)\n",
    "    one_hot = np.zeros((T, vocab_size), dtype=float)\n",
    "    one_hot[np.arange(T), indices] = 1.0\n",
    "    return one_hot\n",
    "\n",
    "def build_sequences(indices: np.ndarray, seq_len: int, vocab_size: int):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for start in range(len(indices) - seq_len):\n",
    "        x_idx = indices[start:start + seq_len]\n",
    "        y_idx = indices[start + 1:start + seq_len + 1]\n",
    "        X_list.append(to_one_hot(x_idx, vocab_size))\n",
    "        y_list.append(y_idx)  # целевые индексы\n",
    "    return np.stack(X_list), np.stack(y_list)\n",
    "\n",
    "def decode_indices(indices: np.ndarray, idx2char: dict[int, str]) -> str:\n",
    "    return \"\".join(idx2char[i] for i in indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2523f0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3736, 20, 23), (3736, 20))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_text = (\n",
    "    \"to be or not to be that is the question whether tis nobler in the mind \"\n",
    "    \"to suffer the slings and arrows of outrageous fortune \"\n",
    "    \"or to take arms against a sea of troubles and by opposing end them \"\n",
    "    \"to die to sleep no more and by a sleep to say we end the heartache \"\n",
    "    \"and the thousand natural shocks that flesh is heir to \"\n",
    ")\n",
    "\n",
    "# Увеличиваем корпус повторением базового текста\n",
    "repeats = 15\n",
    "text = base_text * repeats\n",
    "\n",
    "seq_len = 20\n",
    "\n",
    "char2idx, idx2char = build_vocab(text)\n",
    "vocab_size = len(char2idx)\n",
    "indices = encode_text(text, char2idx)\n",
    "\n",
    "split = int(len(indices) * 0.8)\n",
    "train_idx = indices[:split]\n",
    "test_idx = indices[split:]\n",
    "\n",
    "X_train, y_train = build_sequences(train_idx, seq_len, vocab_size)\n",
    "X_test, y_test = build_sequences(test_idx, seq_len, vocab_size)\n",
    "\n",
    "X_train.shape, y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eadaa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | loss=2.4408\n",
      "epoch=1 | loss=1.5505\n",
      "epoch=2 | loss=0.6147\n",
      "epoch=3 | loss=0.3751\n",
      "epoch=4 | loss=0.3049\n",
      "epoch=5 | loss=0.2712\n",
      "epoch=6 | loss=0.2510\n",
      "epoch=7 | loss=0.2379\n",
      "epoch=8 | loss=0.2284\n",
      "epoch=9 | loss=0.2203\n",
      "epoch=10 | loss=0.2147\n",
      "epoch=11 | loss=0.2099\n",
      "epoch=12 | loss=0.2061\n",
      "epoch=13 | loss=0.2042\n",
      "epoch=14 | loss=0.2011\n",
      "epoch=15 | loss=0.1981\n",
      "epoch=16 | loss=0.1965\n",
      "epoch=17 | loss=0.1955\n",
      "epoch=18 | loss=0.1935\n",
      "epoch=19 | loss=0.1918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lstm.LSTMNextTokenGenerator at 0x1187f5d30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMNextTokenGenerator(\n",
    "    input_dim=vocab_size,\n",
    "    hidden_dim=256,\n",
    "    vocab_size=vocab_size,\n",
    "    lr=1e-3,\n",
    "    max_epochs=20,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7431af6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (next-char): 0.9292\n"
     ]
    }
   ],
   "source": [
    "# Оценка точности предсказания следующего символа\n",
    "probs_test = model.predict_proba(X_test)\n",
    "preds = np.argmax(probs_test, axis=2)\n",
    "correct = (preds == y_test).sum()\n",
    "total = y_test.size\n",
    "print(f\"Test accuracy (next-char): {correct / total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bef3c6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to be or not to be that is the question whetherrt sleee nd no that is the suission whether tis nobler in the mind to suffer the slings and arrows of outrageous fortune or to take arms against a sea of troubles and by op\n"
     ]
    }
   ],
   "source": [
    "def sample(model, seed_text: str, steps: int = 200):\n",
    "    prefix = seed_text\n",
    "    for _ in range(steps):\n",
    "        window = prefix[-seq_len:]\n",
    "        x_idx = np.array([char2idx[ch] for ch in window])\n",
    "        x_vec = to_one_hot(x_idx, vocab_size)\n",
    "        probs = model.predict_next_proba(x_vec)\n",
    "        next_idx = np.random.default_rng().choice(vocab_size, p=probs)\n",
    "        prefix += idx2char[next_idx]\n",
    "    return prefix\n",
    "\n",
    "generated = sample(model, seed_text=\"to be or not to be \")\n",
    "print(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f8065c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
